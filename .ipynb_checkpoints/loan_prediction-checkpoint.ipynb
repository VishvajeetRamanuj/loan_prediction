{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# This program do training on dataset for making decision to give loan or not\n",
    "# It also do Prediction whether to give loan or not for new record\n",
    "# Author: Vishvajeet Ramanuj\n",
    "# Date Created: 26/08/2020\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessory libreries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data from file\n",
    "loan_ds = pd.read_csv('loan_ds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping index as it is not feature and we are using diffrent index for spliting data\n",
    "loan_ds = loan_ds.drop('Loan_ID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spliting data to train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(loan_ds, loan_ds['Loan_Status']):\n",
    "    strat_train_set = loan_ds.loc[train_index]\n",
    "    strat_test_set = loan_ds.loc[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for preprocessing data\n",
    "def preprocess_loan_ds(dataset):\n",
    "    if strat_test_set['Loan_Status'].iloc[0]:\n",
    "        print('spliting labels')\n",
    "        strat_test_set['Loan_Status'].iloc[0]\n",
    "        # spliting labels from data\n",
    "        label = dataset['Loan_Status'].copy()\n",
    "        data = dataset.drop('Loan_Status', axis=1)\n",
    "        label = label == 'Y'\n",
    "    else:\n",
    "        print('only data so no need to split label')\n",
    "        data = dataset\n",
    "\n",
    "    # preprocessing data\n",
    "    # filling balnk value with appropriate value and coverting to boolean datatype where only two options\n",
    "    # first need to fill na values to desired one\n",
    "\n",
    "    # converting dependent object to int\n",
    "    data = data.replace('3+', '3')\n",
    "    median_dependent = data['Dependents'].median()\n",
    "    data['Dependents'].fillna(median_dependent, inplace=True)\n",
    "    data['Dependents'] = data['Dependents'].astype('int')\n",
    "\n",
    "    # preprocessing Married\n",
    "    data['Married'].fillna('Yes', inplace=True)\n",
    "\n",
    "    # converting object to boolean\n",
    "    data.loc[:,'Married'] = data['Married'] == 'Yes'\n",
    "\n",
    "    # preprocessing Gender\n",
    "    data['Gender'].fillna('Male', inplace=True)\n",
    "    data.loc[:, 'Gender'] = data['Gender'] == 'Male' # setting True for Male and False for Female\n",
    "\n",
    "    # preprocessing Education\n",
    "    data.loc[:, 'Education'] = data['Education'] == 'Graduate'\n",
    "\n",
    "    # preprocessing Self_Employed\n",
    "    data['Self_Employed'].fillna('No', inplace=True)\n",
    "    data.loc[:, 'Self_Employed'] = data['Self_Employed'] == 'Yes'\n",
    "\n",
    "    # preprocessing Credit_History\n",
    "    data['Credit_History'].fillna(1, inplace=True)\n",
    "    data.loc[:, 'Credit_History'] = data['Credit_History'] == 1\n",
    "\n",
    "    # preprocessing Loan_Amount_Term\n",
    "    data['Loan_Amount_Term'].fillna(360, inplace=True)\n",
    "    data['Loan_Amount_Term'] = data['Loan_Amount_Term'].astype('int')\n",
    "\n",
    "    # preprocessing LoanAmount\n",
    "#     loan_amt_imputer = SimpleImputer(strategy='mean')\n",
    "#     strat_train_loan_amt = data['LoanAmount'].copy()\n",
    "#     strat_train_loan_amt_1 = strat_train_loan_amt.to_numpy().reshape(-1,1)\n",
    "#     loan_amt_imputer.fit(strat_train_loan_amt_1)\n",
    "\n",
    "#     strat_train_loan_amt_trans = loan_amt_imputer.transform(strat_train_loan_amt_1)\n",
    "\n",
    "    data = data.replace('3+', '3')\n",
    "    median_dependent = data['Dependents'].median()\n",
    "    data['Dependents'].fillna(median_dependent, inplace=True)\n",
    "    data['Dependents'] = data['Dependents'].astype('int')\n",
    "    \n",
    "#     strat_train_loan_amt.mean()\n",
    "    loan_amount_mean = data['LoanAmount'].mean()\n",
    "    data['LoanAmount'] = data['LoanAmount'].fillna(loan_amount_mean)\n",
    "    data['LoanAmount'] = data['LoanAmount'].astype('int')\n",
    "\n",
    "    # preprocessing Property_Area\n",
    "    strat_train_cat = data[['Property_Area']]\n",
    "\n",
    "    cat_encoder = OneHotEncoder(sparse=False)\n",
    "    strat_train_cat_encoded = cat_encoder.fit_transform(strat_train_cat)\n",
    "    \n",
    "    # saving encoder\n",
    "    with open('encoder.txt', 'wb') as f:\n",
    "        pickle.dump(cat_encoder, f)\n",
    "\n",
    "#     data.drop('LoanAmount', axis=1, inplace=True)\n",
    "\n",
    "    # combine data\n",
    "#     loan_amt_df = pd.DataFrame(strat_train_loan_amt_trans, index=data.index, columns=['LoanAmount'])\n",
    "#     strat_train_cat_array = strat_train_cat_encoded\n",
    "    strat_train_cat_df = pd.DataFrame(strat_train_cat_encoded, index=data.index, columns=['Rural', 'Semiurban', 'Urban'])\n",
    "\n",
    "    frames = [data, strat_train_cat_df]\n",
    "    new_ds = pd.concat(frames, axis=1)\n",
    "\n",
    "    new_ds.drop('Property_Area', axis=1, inplace=True)\n",
    "    \n",
    "    if strat_test_set['Loan_Status'].iloc[0]:\n",
    "        return (new_ds, label)\n",
    "    else:\n",
    "        return new_ds\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spliting labels\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels = preprocess_loan_ds(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set\n",
      "original\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Y    0.687296\n",
       "N    0.312704\n",
       "Name: Loan_Status, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying proportation of stratified training set is the same as original dataset\n",
    "print('train set')\n",
    "strat_train_set['Loan_Status'].value_counts() / len(strat_train_set)\n",
    "\n",
    "print('original')\n",
    "loan_ds['Loan_Status'].value_counts() / len(loan_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training Random forest Regressor model\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "forest_reg.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forest_reg.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving traied model\n",
    "joblib.dump(forest_reg, 'forest_reg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spliting labels\n"
     ]
    }
   ],
   "source": [
    "test_data, test_labels = preprocess_loan_ds(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if strat_test_set['Loan_Status'].iloc[0]:\n",
    "#     print('yes')\n",
    "# strat_test_set['Loan_Status'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preprocessing test data\n",
    "# strat_test_label = strat_test_set['Loan_Status'].copy()\n",
    "# strat_test_data = strat_test_set.drop('Loan_Status', axis=1)\n",
    "\n",
    "# # converting dependent object to int\n",
    "# strat_test_data = strat_test_data.replace('3+', '3')\n",
    "# strat_test_data['Dependents'].fillna(median_dependent, inplace=True)\n",
    "# strat_test_data['Dependents'] = strat_test_data['Dependents'].astype('int')\n",
    "\n",
    "# # preprocessing Married\n",
    "# strat_test_data['Married'].fillna('Yes', inplace=True)\n",
    "\n",
    "# # converting object to boolean\n",
    "# strat_test_data.loc[:,'Married'] = strat_test_data['Married'] == 'Yes'\n",
    "\n",
    "# # preprocessing Gender\n",
    "# strat_test_data['Gender'].fillna('Male', inplace=True)\n",
    "# strat_test_data.loc[:, 'Gender'] = strat_test_data['Gender'] == 'Male'\n",
    "\n",
    "# # preprocessing Education\n",
    "# strat_test_data.loc[:, 'Education'] = strat_test_data['Education'] == 'Graduate'\n",
    "\n",
    "# # preprocessing Self_Employed\n",
    "# strat_test_data['Self_Employed'].fillna('No', inplace=True)\n",
    "# strat_test_data.loc[:, 'Self_Employed'] = strat_test_data['Self_Employed'] == 'Yes'\n",
    "\n",
    "# # preprocessing Credit_History\n",
    "# strat_test_data['Credit_History'].fillna(1, inplace=True)\n",
    "# strat_test_data.loc[:, 'Credit_History'] = strat_test_data['Credit_History'] == 1\n",
    "\n",
    "# # preprocessing Loan_Amount_Term\n",
    "# strat_test_data['Loan_Amount_Term'].fillna(360, inplace=True)\n",
    "# strat_test_data['Loan_Amount_Term'] = strat_test_data['Loan_Amount_Term'].astype('int')\n",
    "\n",
    "# mean = 147.30997877\n",
    "# # LoanAmout\n",
    "# strat_test_data['LoanAmount'].fillna(mean, inplace=True)\n",
    "\n",
    "# # preprocessing Property_Area\n",
    "# strat_test_cat = strat_test_data[['Property_Area']]\n",
    "# strat_test_cat_encoded = cat_encoder.transform(strat_test_cat)\n",
    "\n",
    "# # combining encoded category with dataset\n",
    "# strat_test_cat_array = strat_test_cat_encoded\n",
    "# strat_test_cat_df = pd.DataFrame(strat_test_cat_array, index=strat_test_data.index, columns=['Rural', 'Semiurban', 'Urban'])\n",
    "\n",
    "# frames = [strat_test_data, strat_test_cat_df]\n",
    "# new_ds_test = pd.concat(frames, axis=1)\n",
    "\n",
    "# new_ds_test.drop('Property_Area', axis=1, inplace=True)\n",
    "\n",
    "# # new_ds\n",
    "\n",
    "# strat_test_label = strat_test_label == 'Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = forest_reg.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions\n",
    "score = accuracy_score(test_labels, predictions.round(), normalize=False)\n",
    "score # there must be something wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo new label prediction\n",
    "a = [['Urban']]\n",
    "type(a)\n",
    "# print(a)\n",
    "# cat_encoder.transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading encoder\n",
    "file = open('encoder.txt', 'rb')\n",
    "cat_encoder = pickle.load(file)\n",
    "\n",
    "# loading model\n",
    "forest_reg = joblib.load(\"forest_reg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Prediction\n",
    "ID = \"LP002991\"\n",
    "Gender = \"Male\"\n",
    "Married = \"Yes\"\n",
    "Dependents = 2\n",
    "Education = \"Graduate\"\n",
    "Self_Employed = \"Yes\"\n",
    "ApplicantIncome = 5000\n",
    "CoapplicantIncome = 2000\n",
    "LoanAmount = 250\n",
    "Loan_Amount_Term = 360\n",
    "Credit_History = 1\n",
    "Property_Area = \"Urban\"\n",
    "# Loan_Status = ?\n",
    "\n",
    "def loan_grant_decision(ID, ApplicantIncome, CoapplicantIncome, Property_Area, Gender=\"Male\", Married=\"Yes\", \n",
    "                        Dependents=0, Education = \"Graduate\", Self_Employed='No',\n",
    "                        LoanAmount=147, Loan_Amount_Term=360, Credit_History='Yes', threshhold=0.70\n",
    "                        ):\n",
    "    # spliting labels from data\n",
    "    loan_data = pd.DataFrame([[\n",
    "                              Gender, Married, Dependents, Education, Self_Employed, \n",
    "                              ApplicantIncome, CoapplicantIncome, LoanAmount, Loan_Amount_Term, \n",
    "                              Credit_History, Property_Area\n",
    "                             ]], \n",
    "                             columns = [\n",
    "                              'Gender', 'Married', 'Dependents', 'Education', 'Self_Employed',\n",
    "                              'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
    "                              'Loan_Amount_Term', 'Credit_History', 'Property_Area'\n",
    "                             ])\n",
    "\n",
    "    # converting object to boolean\n",
    "    \n",
    "    loan_data.loc[:, 'Married'] = loan_data['Married'] == 'Yes'\n",
    "\n",
    "    # preprocessing Gender\n",
    "    loan_data.loc[:, 'Gender'] = loan_data['Gender'] == 'Male'\n",
    "\n",
    "    # preprocessing Education\n",
    "    loan_data.loc[:, 'Education'] = loan_data['Education'] == 'Graduate'\n",
    "\n",
    "    # preprocessing Self_Employed\n",
    "    loan_data.loc[:, 'Self_Employed'] = loan_data['Self_Employed'] == 'Yes'\n",
    "\n",
    "    # preprocessing Credit_History\n",
    "    loan_data.loc[:, 'Credit_History'] = loan_data['Credit_History'] == 1\n",
    "    loan_data_cat = loan_data['Property_Area'].to_numpy().reshape(-1,1)\n",
    "\n",
    "    loan_data_cat_encoded = cat_encoder.transform(loan_data_cat)\n",
    "    loan_data_cat_array = loan_data_cat_encoded\n",
    "    loan_data_cat_df = pd.DataFrame(loan_data_cat_array, index=loan_data.index, columns=['Rural', 'Semiurban', 'Urban'])\n",
    "\n",
    "    frames = [loan_data, loan_data_cat_df]\n",
    "    new_ds = pd.concat(frames, axis=1)\n",
    "\n",
    "    new_ds.drop('Property_Area', axis=1, inplace=True)\n",
    "#     new_ds = preprocess_loan_ds(loan_ds) # you can replace above preprocessing with this function\n",
    "    prediction = forest_reg.predict(new_ds)\n",
    "    if prediction[0] >= threshhold:\n",
    "        return True # grant loan\n",
    "    else:\n",
    "        return False # do not grant loan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = loan_grant_decision(ID, ApplicantIncome, CoapplicantIncome, Property_Area, Gender=Gender, Married=Married, \n",
    "                             Dependents=Dependents, Education = Education,\n",
    "                             Self_Employed=Self_Employed, LoanAmount=LoanAmount,\n",
    "                             Loan_Amount_Term=Loan_Amount_Term, Credit_History=Credit_History)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spliting labels\n"
     ]
    }
   ],
   "source": [
    "# Retrain\n",
    "\n",
    "\n",
    "\n",
    "# reading new_csv\n",
    "new_dataset = pd.read_csv('loan_ds_2.csv')\n",
    "\n",
    "# droping index as it is not feature and we are using diffrent index for spliting data\n",
    "new_dataset = new_dataset.drop('Loan_ID', axis=1)\n",
    "\n",
    "# spliting data into training and test set\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(loan_ds, loan_ds['Loan_Status']):\n",
    "    strat_train_set = loan_ds.loc[train_index]\n",
    "    strat_test_set = loan_ds.loc[test_index]\n",
    "\n",
    "# pre process data    \n",
    "train_data, train_labels = preprocess_loan_ds(strat_train_set)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store previous pre process data in csv\n",
    "# load previous pre_process data\n",
    "# combine both dataframe\n",
    "# do preprocessing\n",
    "# do training\n",
    "# save new preprcess data, and model for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spliting labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['forest_reg.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_dataset = pd.read_csv('loan_ds.csv')\n",
    "\n",
    "combine_ds = pd.concat([old_dataset, new_dataset])\n",
    "\n",
    "# do preprocessing\n",
    "combine_ds_data, combine_ds_labels = preprocess_loan_ds(combine_ds)\n",
    "\n",
    "# we are creating new model which will be trained on all data\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42) \n",
    "forest_reg.fit(train_data, train_labels)\n",
    "\n",
    "# saving new model\n",
    "joblib.dump(forest_reg, 'forest_reg.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
